# Transformer_examples

Examples of NLP tasks using pretrained transformers 

1) Sequence classification : classifying sequences according to a given number of classes.
2) Extractive Question Answering :  extracting an answer from a text given a question.
3) Masked Language Model : masking tokens in a sequence with a masking token, and prompting the model to fill that mask with an appropriate token.
4) Casual Language Model : predicting the token following a sequence of tokens.
5) Text Generation : creating a coherent portion of text that is a continuation from the given context.
6) Name Entity Recognition : classifying tokens according to a class, for example, identifying a token as a person, an organisation or a location.
7) Summerization : summarizing a document or an article into a shorter text.
8) Translation : translating a text from one language to another.
9) Image Classification : assigning a class to an image.

Adapted and modified from https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb 

